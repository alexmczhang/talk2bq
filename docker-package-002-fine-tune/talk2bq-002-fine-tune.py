import pandas
import vertexai
from vertexai.language_models import TextGenerationModel
from google.cloud import bigquery

project_id = "hello-world-360207"  # @param {type:"string"}
project_number = "334845241623" # @param {type:"string"}
location = "us-central1"  # @param {type:"string"}

vertexai.init(location=location, project=project_number)
bqClient = bigquery.Client(location=location, project=project_id)

sample_df = pandas.DataFrame({
    'Weight':[45, 88, 56, 15, 71], 
    'Name':['Sam', 'Andrea', 'Alex', 'Robin', 'Kia'], 
    'Age':[14, 25, 55, 8, 21]}) 

# initialize LLM()
parameters = {
    "candidate_count": 1,
    "max_output_tokens": 1024,
    "temperature": 0.2,
    "top_p": 0.8,
    "top_k": 40
}
model = TextGenerationModel.from_pretrained("text-bison@002")
model = model.get_tuned_model("projects/334845241623/locations/us-central1/models/2796539655527333888")

nlq_prompt = """
You are a GoogleSQL expert. Given an input question, first create a syntactically correct GoogleSQL query to run, then look at the results of the query and return the answer to the input question. 

Unless the user specifies in the question a specific number of examples to obtain, query for at most 10000 results using the LIMIT clause as per GoogleSQL. You can order the results to return the most informative data in the database. 

Never query for all columns from a table. You must query only the columns that are needed to answer the question. Wrap each column name in backticks (`) to denote them as delimited identifiers

input: {input}
output:
"""

def bq_talker(question):
    # nlq_input = "In the 2008/2009 season, which top 10 teams scored the most goals ?"
    prompt = nlq_prompt.format(input=question)
    
    response = model.predict(prompt, **parameters)
    
    bqSqlQuery = response.text
    print(f"Response from Model: {response.text}")
    
    df = pandas.read_gbq(bqSqlQuery, dialect="standard", use_bqstorage_api=True)
    return df, bqSqlQuery


def showBarPlot(df_plot):
    #df = convertToDataframe(strDataFrame)
    #df = df.rename(columns={0: 'Club', 1: 'Goals'})
    
    #for docker / cloud run env
    #return gr.BarPlot(
    #for jupyter notebook env
    # return gr.BarPlot.update(
    return gr.BarPlot(
        df_plot,
        x="team_long_name",
        y="total_goals_scored",
        color="total_goals_scored",
        title="2008/2009 season, top 10 teams in terms of goals scored",
        tooltip=["team_long_name", "total_goals_scored"],
        width = 800,
        # y_lim=[20, 100],
    )

import gradio as gr

with gr.Blocks() as ui:
    gr.Markdown(
    """
    ## Ask BiqQuery [text-bison@002 + fine tuned]

    This demo is to showcase answering questions on a tabular data available in Big Query using Vertex PALM LLM & Langchain.

    This demo uses a sample public dataset from Kaggle (https://www.kaggle.com/datasets/hugomathien/soccer)

    ### Sample Inputs:
    1. What is short name for FC Barcelona ?
    2. In the 2008/2009 season, who are the top 10 teams in terms of goals scored?
    3. In the 2008/2009 season, who are the top 10 teams in terms of goals scored, and how many goals they scored at home and away?
    4. How many matches FC Barcelona won in the 2008/2009 season as home team ?
    5. Here is the rule for each match, win = 3 points, draw = 1 point, lost = 0 point. how many points FC Barcelona had for season 2008/2009

    ### Enter a search query...

    """)
    
    
    with gr.Row():
        with gr.Column():
            input_text=gr.Textbox(label="Question", value="In the 2008/2009 season, who are the top 10 teams in terms of goals scored?")
            
    with gr.Row():
      btnTalk2bq = gr.Button("Talk to BigQuery")

    #with gr.Row():
    #  lbl_output = gr.Textbox(label="Output")
    
    with gr.Row():
      lbl_sqlscript = gr.Textbox(label="SQL query generated by LLM")
    
    with gr.Row():
      #lbl_sqlresult = gr.Textbox(label="Data fetched by SQL scipt that generated by LLM")
      df_tableau = gr.DataFrame(value=sample_df, label="Data fetched by SQL scipt that generated by LLM")
        
            
    with gr.Row():
      btnShowBarPlot = gr.Button("Show Bar Plot")
        
    with gr.Row():
      plot = gr.BarPlot()
    
    with gr.Row():
      gr.Image("http://34.160.193.190/arch-bison@002-fine-tune.jpg")
    
    
    btnShowBarPlot.click(showBarPlot, df_tableau, outputs=plot)
    btnTalk2bq.click(bq_talker, input_text, [df_tableau, lbl_sqlscript])

#ui.launch(server_name="0.0.0.0", server_port=1234, share=True, debug=True)
ui.launch(server_name="0.0.0.0", server_port=8080, share=True, debug=False)


# In[ ]:


#question = "In the 2008/2009 season, which top 10 teams scored the most goals ?"
#df, bqSqlQuery = bq_talker(question)

#bgSqlQuery = """
#SELECT COUNT(home_team_goal) AS home_team_goal_count FROM `demo_talk2bq.match` AS m JOIN `demo_talk2bq.team` AS t ON m.home_team_api_id = t.team_api_id WHERE m.season = '2008/2009' AND t.team_long_name = 'FC Barcelona' AND m.home_team_goal > m.away_team_goal LIMIT 10000;
#"""

#bqClient = bigquery.Client(location="us-central1", project="hello-world-360207")

#df = pandas.read_gbq(bqSqlQuery, dialect="standard", use_bqstorage_api=True)


# @title Specify Project details and location of the BQ table

#project_id = "hello-world-360207"  # @param {type:"string"}
#location = "us-central1"  # @param {type:"string"}
#dataset_id = 'demo_talk2bq' # @param {type:"string"}
#table_name1 = 'country' # @param {type:"string"}
#table_name2 = 'league' # @param {type:"string"}
#table_name3 = 'player' # @param {type:"string"}
#table_name4 = 'team' # @param {type:"string"}
#table_name5 = 'match' # @param {type:"string"}

#table_names = (table_name1, table_name2, table_name3, table_name4, table_name5)

#setup bigquery engine
#table_uri = f"bigquery://{project_id}/{dataset_id}"
#bq_engine = create_engine(f"bigquery://{project_id}/{dataset_id}")

